{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-scraping for Lego images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for downloading images\n",
    "def dl_jpg(url, file_path, file_name):\n",
    "    full_path = file_path + file_name + \".jpg\"\n",
    "    urllib.request.urlretrieve(url, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping basic content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries with page URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_pages = dict()\n",
    "dup_pages = dict()\n",
    "tech_pages = dict()\n",
    "\n",
    "# Change the number of pages depending on how many ads you want to scrape.\n",
    "for i in range(0, 5):\n",
    "    if i == 0:\n",
    "        sw_page = \"https://www.ricardo.ch/de/c/lego-star-wars-70601/?item_condition=used\"\n",
    "        sw_pages.update({i: sw_page})\n",
    "        duplo_page = \"https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used\"\n",
    "        dup_pages.update({i: duplo_page})\n",
    "        tech_page = \"https://www.ricardo.ch/de/c/lego-technik-41822/?item_condition=used\"\n",
    "        tech_pages.update({i: tech_page})\n",
    "        \n",
    "    else:\n",
    "        sw_page = f\"https://www.ricardo.ch/de/c/lego-star-wars-70601/?item_condition=used&next_offset={i*59}&page={i+1}\"\n",
    "        sw_pages.update({i: sw_page})\n",
    "        duplo_page = f\"https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used&next_offset={(i*59)+1}&page={i+1}\"\n",
    "        dup_pages.update({i: duplo_page})\n",
    "        tech_page = f\"https://www.ricardo.ch/de/c/lego-technik-41822/?item_condition=used&next_offset={(i*59)+1}&page={i+1}\"\n",
    "        tech_pages.update({i: tech_page})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used',\n",
       " 1: 'https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used&next_offset=60&page=2',\n",
       " 2: 'https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used&next_offset=119&page=3',\n",
       " 3: 'https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used&next_offset=178&page=4',\n",
       " 4: 'https://www.ricardo.ch/de/c/duplo-41818/?item_condition=used&next_offset=237&page=5'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape content for each line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starwars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape pages\n",
    "starwars_pages = list()\n",
    "\n",
    "for i in range(len(sw_pages)):\n",
    "    page_html = requests.get(sw_pages[i], timeout = 3)\n",
    "    page_content = BeautifulSoup(page_html.content, \"html.parser\")\n",
    "    starwars_pages.append(page_content)\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract box with ad url\n",
    "starwars_a = list()\n",
    "\n",
    "for i in range(len(starwars_pages)):\n",
    "    a = starwars_pages[i].findAll(\"a\", \n",
    "        {\"class\": \"MuiGrid-root link--2etfD MuiGrid-item MuiGrid-grid-xs-6 MuiGrid-grid-sm-4 MuiGrid-grid-md-3\"})\n",
    "    starwars_a.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the urls\n",
    "starwars_href = list()\n",
    "\n",
    "for i in range(len(starwars_a)):\n",
    "    for j in range(len(starwars_a[0])):\n",
    "        sw_href = starwars_a[i][j].get(\"href\")\n",
    "        starwars_href.append(f\"https://www.ricardo.ch{sw_href}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape individual ads\n",
    "starwars_ads = list()\n",
    "starwars_time = list()\n",
    "\n",
    "for i in range(0, 300):\n",
    "    page_html = requests.get(starwars_href[i], timeout = 3)\n",
    "    page_content = BeautifulSoup(page_html.content, \"html.parser\")\n",
    "    starwars_ads.append(page_content)\n",
    "    starwars_time.append(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))   # Add the time of scraping.\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the contents and timestamp\n",
    "for i, j in zip(range(len(starwars_ads)), starwars_ads):\n",
    "    filename = f\"starwars_ads_{i}.html\"\n",
    "    path = \"html/\"\n",
    "    with open(path + filename, \"w\") as file:\n",
    "        file.write(str(j))\n",
    "        \n",
    "starwars_time = pd.Series(starwars_time)\n",
    "starwars_time.to_csv(\"timestamp_sw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the image box\n",
    "starwars_jpegs = list()\n",
    "\n",
    "for i in range(len(starwars_ads)):\n",
    "    if starwars_ads[i].findAll(\"img\", {\"class\": \"jss156\"}):\n",
    "        image = starwars_ads[i].findAll(\"img\", {\"class\": \"jss156\"})\n",
    "        starwars_jpegs.append(image)\n",
    "    elif starwars_ads[i].findAll(\"img\", {\"class\": \"jss164\"}):\n",
    "        image = starwars_ads[i].findAll(\"img\", {\"class\": \"jss164\"})\n",
    "        starwars_jpegs.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists\n",
    "flat_starwars_jpegs = []\n",
    "\n",
    "for sublist in starwars_jpegs:\n",
    "    if not sublist:\n",
    "        flat_starwars_jpegs.append(\"NaN\")\n",
    "    else:\n",
    "        for item in sublist:\n",
    "            flat_starwars_jpegs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save URLs and ad titles\n",
    "starwars_jpegs_links = list()\n",
    "list_starwars_titles = list()\n",
    "list_starwars_line = list()\n",
    "\n",
    "for i in range(len(flat_starwars_jpegs)):\n",
    "    if flat_starwars_jpegs[i] == \"NaN\":\n",
    "        starwars_jpegs_links.append(\"NaN\")\n",
    "    else:\n",
    "        source = flat_starwars_jpegs[i].get(\"src\")\n",
    "        starwars_jpegs_links.append(source)\n",
    "\n",
    "    if flat_starwars_jpegs[i] == \"NaN\":\n",
    "        list_starwars_titles.append(\"NaN\")\n",
    "    else:\n",
    "        title = flat_starwars_jpegs[i].get(\"alt\")\n",
    "        list_starwars_titles.append(title)\n",
    "\n",
    "    line = \"starwars\"\n",
    "    list_starwars_line.append(line)\n",
    "\n",
    "lego_sw_df = pd.DataFrame({\"line\": list_starwars_line, \"title\": list_starwars_titles, \"image_url\": \n",
    "                           starwars_jpegs_links, \"scraped_at\": starwars_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to the drive\n",
    "for i in range(len(lego_sw_df)):\n",
    "    if lego_sw_df[\"image_url\"][i] == \"missing\":\n",
    "        pass\n",
    "    else:\n",
    "        url = lego_sw_df[\"image_url\"][i]\n",
    "        file_name = f\"{datetime.now().strftime('%Y%m%d')}_legoset_{i}\"\n",
    "        dl_jpg(url, \"images/\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape pages\n",
    "duplo_pages = list()\n",
    "\n",
    "for i in range(len(dup_pages)):\n",
    "    page_html = requests.get(dup_pages[i], timeout = 3)\n",
    "    page_content = BeautifulSoup(page_html.content, \"html.parser\")\n",
    "    duplo_pages.append(page_content)\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract box with ad url\n",
    "duplo_a = list()\n",
    "\n",
    "for i in range(len(duplo_pages)):\n",
    "    a = duplo_pages[i].findAll(\"a\", \n",
    "        {\"class\": \"MuiGrid-root link--2etfD MuiGrid-item MuiGrid-grid-xs-6 MuiGrid-grid-sm-4 MuiGrid-grid-md-3\"})\n",
    "    duplo_a.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the urls\n",
    "duplo_href = list()\n",
    "\n",
    "for i in range(len(duplo_a)):\n",
    "    for j in range(len(duplo_a[0])):\n",
    "        dp_href = duplo_a[i][j].get(\"href\")\n",
    "        duplo_href.append(f\"https://www.ricardo.ch{dp_href}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape individual ads\n",
    "duplo_ads = list()\n",
    "duplo_time = list()\n",
    "\n",
    "for i in range(0, 300):\n",
    "    page_html = requests.get(duplo_href[i], timeout = 3)\n",
    "    page_content = BeautifulSoup(page_html.content, \"html.parser\")\n",
    "    duplo_ads.append(page_content)\n",
    "    duplo_time.append(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the contents and timestamp\n",
    "for i, j in zip(range(len(duplo_ads)), duplo_ads):\n",
    "    filename = f\"duplo_ads_{i}.html\"\n",
    "    path = \"html/\"\n",
    "    with open(path + filename, \"w\") as file:\n",
    "        file.write(str(j))\n",
    "        \n",
    "duplo_time = pd.Series(duplo_time)\n",
    "duplo_time.to_csv(\"timestamp_duplo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the image box\n",
    "duplo_jpegs = list()\n",
    "\n",
    "for i in range(len(duplo_ads)):\n",
    "    if duplo_ads[i].findAll(\"img\", {\"class\": \"jss156\"}):\n",
    "        image = duplo_ads[i].findAll(\"img\", {\"class\": \"jss156\"})\n",
    "        duplo_jpegs.append(image)\n",
    "    elif duplo_ads[i].findAll(\"img\", {\"class\": \"jss164\"}):\n",
    "        image = duplo_ads[i].findAll(\"img\", {\"class\": \"jss164\"})\n",
    "        duplo_jpegs.append(image)\n",
    "    else:\n",
    "        duplo_jpegs.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists\n",
    "flat_duplo_jpegs = []\n",
    "\n",
    "for sublist in duplo_jpegs:\n",
    "    if not sublist:\n",
    "        flat_duplo_jpegs.append(\"NaN\")\n",
    "    else:\n",
    "        for item in sublist:\n",
    "            flat_duplo_jpegs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save URLs and ad titles\n",
    "duplo_jpegs_links = list()\n",
    "list_duplo_titles = list()\n",
    "list_duplo_line = list()\n",
    "\n",
    "for i in range(len(flat_duplo_jpegs)):\n",
    "    if flat_duplo_jpegs[i] == \"NaN\":\n",
    "        duplo_jpegs_links.append(\"NaN\")\n",
    "    else:\n",
    "        source = flat_duplo_jpegs[i].get(\"src\")\n",
    "        duplo_jpegs_links.append(source)\n",
    "    \n",
    "    if flat_duplo_jpegs[i] == \"NaN\":\n",
    "        list_duplo_titles.append(\"NaN\")\n",
    "    else:\n",
    "        title = flat_duplo_jpegs[i].get(\"alt\")\n",
    "        list_duplo_titles.append(title)\n",
    "    \n",
    "    line = \"duplo\"\n",
    "    list_duplo_line.append(line)\n",
    "    \n",
    "lego_duplo_df = pd.DataFrame({\"line\": list_duplo_line, \"title\": list_duplo_titles, \"image_url\": \n",
    "                              duplo_jpegs_links, \"scraped_at\": duplo_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to the drive\n",
    "for i in range(len(lego_duplo_df)):\n",
    "    if lego_duplo_df[\"image_url\"][i] == \"NaN\":\n",
    "        pass\n",
    "    else:\n",
    "        url = lego_duplo_df[\"image_url\"][i]\n",
    "        file_name = f\"{datetime.now().strftime('%Y%m%d')}_legoset_{i + len(lego_sw_df)}\"\n",
    "        dl_jpg(url, \"images/\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape pages\n",
    "technic_pages = list()\n",
    "\n",
    "for i in range(len(tech_pages)):\n",
    "    page_html = requests.get(tech_pages[i], timeout = 3)\n",
    "    page_content = BeautifulSoup(page_html.content, \"html.parser\")\n",
    "    technic_pages.append(page_content)\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract box with ad url\n",
    "technic_a = list()\n",
    "\n",
    "for i in range(len(technic_pages)):\n",
    "    a = technic_pages[i].findAll(\"a\", \n",
    "        {\"class\": \"MuiGrid-root link--2etfD MuiGrid-item MuiGrid-grid-xs-6 MuiGrid-grid-sm-4 MuiGrid-grid-md-3\"})\n",
    "    technic_a.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the urls\n",
    "technic_href = list()\n",
    "\n",
    "for i in range(len(technic_a)):\n",
    "    for j in range(len(technic_a[0])):\n",
    "        tc_href = technic_a[i][j].get(\"href\")\n",
    "        technic_href.append(f\"https://www.ricardo.ch{tc_href}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape individual ads\n",
    "technic_ads = list()\n",
    "technic_time = list()\n",
    "\n",
    "for i in range(0, 300):\n",
    "    page_html = requests.get(technic_href[i], timeout = 3)\n",
    "    page_content = BeautifulSoup(page_html.content, \"html.parser\")\n",
    "    technic_ads.append(page_content)\n",
    "    technic_time.append(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the contents and timestamp\n",
    "for i, j in zip(range(len(technic_ads)), technic_ads):\n",
    "    filename = f\"technic_ads_{i}.html\"\n",
    "    path = \"html/\"\n",
    "    with open(path + filename, \"w\") as file:\n",
    "        file.write(str(j))\n",
    "\n",
    "technic_time = pd.Series(technic_time)\n",
    "technic_time.to_csv(\"timestamp_technic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the image box\n",
    "technic_jpegs = list()\n",
    "\n",
    "for i in range(len(technic_ads)):\n",
    "    if technic_ads[i].findAll(\"img\", {\"class\": \"jss156\"}):\n",
    "        image = technic_ads[i].findAll(\"img\", {\"class\": \"jss156\"})\n",
    "        technic_jpegs.append(image)\n",
    "    elif technic_ads[i].findAll(\"img\", {\"class\": \"jss164\"}):\n",
    "        image = technic_ads[i].findAll(\"img\", {\"class\": \"jss164\"})\n",
    "        technic_jpegs.append(image)\n",
    "    else:\n",
    "        technic_jpegs.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technic_jpegs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists\n",
    "flat_technic_jpegs = []\n",
    "\n",
    "for sublist in technic_jpegs:\n",
    "    if not sublist:\n",
    "        flat_technic_jpegs.append(\"NaN\")\n",
    "    else:\n",
    "        for item in sublist:\n",
    "            flat_technic_jpegs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save URLs and ad titles\n",
    "technic_jpegs_links = list()\n",
    "list_technic_titles = list()\n",
    "list_technic_line = list()\n",
    "\n",
    "for i in range(len(flat_technic_jpegs)):\n",
    "    if flat_technic_jpegs[i] == \"NaN\":\n",
    "        technic_jpegs_links.append(\"NaN\")\n",
    "    else:\n",
    "        source = flat_technic_jpegs[i].get(\"src\")\n",
    "        technic_jpegs_links.append(source)\n",
    "    \n",
    "    if flat_technic_jpegs[i] == \"NaN\":\n",
    "        list_technic_titles.append(\"NaN\")\n",
    "    else:\n",
    "        title = flat_technic_jpegs[i].get(\"alt\")\n",
    "        list_technic_titles.append(title)\n",
    "    \n",
    "    line = \"technic\"\n",
    "    list_technic_line.append(line)\n",
    "    \n",
    "lego_tech_df = pd.DataFrame({\"line\": list_technic_line, \"title\": list_technic_titles, \"image_url\": \n",
    "                             technic_jpegs_links, \"scraped_at\": technic_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images to the drive\n",
    "for i in range(len(lego_tech_df)):\n",
    "    if lego_tech_df[\"image_url\"][i] == \"NaN\":\n",
    "        pass\n",
    "    else:\n",
    "        url = lego_tech_df[\"image_url\"][i]\n",
    "        file_name = f\"{datetime.now().strftime('%Y%m%d')}_legoset_{i + len(lego_sw_df) + len(lego_duplo_df)}\"\n",
    "        dl_jpg(url, \"images/\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lego_sw_df), len(lego_duplo_df), len(lego_tech_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the three lines\n",
    "lego_df = pd.concat([lego_sw_df, lego_duplo_df, lego_tech_df], ignore_index=True)\n",
    "lego_df[\"scraped_at\"] = pd.to_datetime(lego_df[\"scraped_at\"])\n",
    "lego_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one column for the image name\n",
    "image_name = list()\n",
    "\n",
    "for i in range(len(lego_df)):\n",
    "    file_name = f\"{i}_legosets.jpg\"\n",
    "    image_name.append(file_name)\n",
    "\n",
    "lego_df[\"image_name\"] = image_name\n",
    "lego_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the info box with interesting information\n",
    "starwars_info = list()\n",
    "duplo_info = list()\n",
    "technic_info = list()\n",
    "\n",
    "for i in range(len(starwars_ads)):\n",
    "    info = starwars_ads[i].findAll(\"div\", {\"class\": \"mainInfo--hdpPQ\"})\n",
    "    starwars_info.append(info)\n",
    "    \n",
    "    info = duplo_ads[i].findAll(\"div\", {\"class\": \"mainInfo--hdpPQ\"})\n",
    "    duplo_info.append(info)\n",
    "    \n",
    "    info = technic_ads[i].findAll(\"div\", {\"class\": \"mainInfo--hdpPQ\"})\n",
    "    technic_info.append(info)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_starwars_info = []   ### Replace empty lists with string 'NaN'.\n",
    "for sublist in starwars_info:\n",
    "    if not sublist:\n",
    "        flat_starwars_info.append(\"NaN\")\n",
    "    else:\n",
    "        for item in sublist:\n",
    "            flat_starwars_info.append(item)\n",
    "            \n",
    "flat_duplo_info = []\n",
    "for sublist in duplo_info:\n",
    "    if not sublist:\n",
    "        flat_duplo_info.append(\"NaN\")\n",
    "    else:\n",
    "        for item in sublist:\n",
    "            flat_duplo_info.append(item)\n",
    "            \n",
    "flat_technic_info = []\n",
    "for sublist in technic_info:\n",
    "    if not sublist:\n",
    "        flat_technic_info.append(\"NaN\")\n",
    "    else:\n",
    "        for item in sublist:\n",
    "            flat_technic_info.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_missing = 0\n",
    "for i in flat_starwars_info:\n",
    "    if i == 'NaN':\n",
    "        sw_missing = sw_missing + 1\n",
    "\n",
    "dup_missing = 0\n",
    "for i in flat_duplo_info:\n",
    "    if i == 'NaN':\n",
    "        dup_missing = dup_missing + 1\n",
    "\n",
    "tech_missing = 0\n",
    "for i in flat_technic_info:\n",
    "    if i == 'NaN':\n",
    "        tech_missing = tech_missing + 1\n",
    "\n",
    "print(f\"Star Wars: {sw_missing/len(flat_starwars_info)*100}% missing\")\n",
    "print(f\"Duplo: {dup_missing/len(flat_duplo_info)*100}% missing\")\n",
    "print(f\"Technic: {tech_missing/len(flat_technic_info)*100}% missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next bid and purchase price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_bid_auction = list()\n",
    "\n",
    "for i in range(len(flat_starwars_info)):\n",
    "    if flat_starwars_info[i].find(\"input\", {\"class\": \"jss176 jss175\"}):\n",
    "        price = flat_starwars_info[i].find(\"input\", {\"class\": \"jss176 jss175\"}).get(\"value\")\n",
    "        next_bid_auction.append(price)\n",
    "    \n",
    "    elif flat_starwars_info[i].find(\"input\", {\"class\": \"jss173 jss172\"}):\n",
    "        price = flat_starwars_info[i].find(\"input\", {\"class\": \"jss173 jss172\"}).get(\"value\")\n",
    "        next_bid_auction.append(price)\n",
    "    \n",
    "    else:\n",
    "        next_bid_auction.append(\"NaN\")\n",
    "\n",
    "for i in range(len(flat_duplo_info)):\n",
    "    if flat_duplo_info[i].find(\"input\", {\"class\": \"jss176 jss175\"}):\n",
    "        price = flat_duplo_info[i].find(\"input\", {\"class\": \"jss176 jss175\"}).get(\"value\")\n",
    "        next_bid_auction.append(price)\n",
    "        \n",
    "    elif flat_duplo_info[i].find(\"input\", {\"class\": \"jss173 jss172\"}):\n",
    "        price = flat_duplo_info[i].find(\"input\", {\"class\": \"jss173 jss172\"}).get(\"value\")\n",
    "        next_bid_auction.append(price)\n",
    "        \n",
    "    else:\n",
    "        next_bid_auction.append(\"NaN\")\n",
    "\n",
    "for i in range(len(flat_technic_info)):\n",
    "    if flat_technic_info[i].find(\"input\", {\"class\": \"jss176 jss175\"}):\n",
    "        price = flat_technic_info[i].find(\"input\", {\"class\": \"jss176 jss175\"}).get(\"value\")\n",
    "        next_bid_auction.append(price)\n",
    "        \n",
    "    elif flat_technic_info[i].find(\"input\", {\"class\": \"jss173 jss172\"}):\n",
    "        price = flat_technic_info[i].find(\"input\", {\"class\": \"jss173 jss172\"}).get(\"value\")\n",
    "        next_bid_auction.append(price)\n",
    "    \n",
    "    else:\n",
    "        next_bid_auction.append(\"NaN\")\n",
    "        \n",
    "next_bid_auction[25:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_buy_now = list()\n",
    "\n",
    "for i in range(len(flat_starwars_info)):\n",
    "    if flat_starwars_info[i].find(\"div\", {\"class\": \"price--rC2BI\"}):\n",
    "        price = flat_starwars_info[i].find(\"div\", {\"class\": \"price--rC2BI\"}).get_text()\n",
    "        price_buy_now.append(price)\n",
    "    else:\n",
    "        price_buy_now.append(\"NaN\")\n",
    "\n",
    "for i in range(len(flat_duplo_info)):\n",
    "    if flat_duplo_info[i].find(\"div\", {\"class\": \"price--rC2BI\"}):\n",
    "        price = flat_duplo_info[i].find(\"div\", {\"class\": \"price--rC2BI\"}).get_text()\n",
    "        price_buy_now.append(price)\n",
    "    else:\n",
    "        price_buy_now.append(\"NaN\")\n",
    "        \n",
    "for i in range(len(flat_technic_info)):\n",
    "    if flat_technic_info[i].find(\"div\", {\"class\": \"price--rC2BI\"}):\n",
    "        price = flat_technic_info[i].find(\"div\", {\"class\": \"price--rC2BI\"}).get_text()\n",
    "        price_buy_now.append(price)\n",
    "    else:\n",
    "        price_buy_now.append(\"NaN\")\n",
    "\n",
    "price_buy_now[25:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lego_df[\"next_bid_auction\"] = next_bid_auction\n",
    "lego_df[\"next_bid_auction\"] = lego_df[\"next_bid_auction\"].astype(float)\n",
    "\n",
    "lego_df[\"price_buy_now\"] = price_buy_now\n",
    "lego_df[\"price_buy_now\"] = lego_df[\"price_buy_now\"].astype(float)\n",
    "\n",
    "lego_df.iloc[40,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End date and time remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = list()\n",
    "\n",
    "for i in range(len(flat_starwars_info)):\n",
    "    if flat_starwars_info[i].findAll(\"span\", {\"class\": \"jss171\"}):\n",
    "        date = flat_starwars_info[i].findAll(\"span\", {\"class\": \"jss171\"})\n",
    "        date_stripped = date[0].get_text().strip(\"schedule\").replace(\"Dez\", \"Dec\")\n",
    "        \n",
    "        if len(date_stripped) > 25:\n",
    "            date_stripped = date_stripped[date_stripped.find('|'):].strip(\"| \")\n",
    "        \n",
    "        date_stripped = datetime.strptime(date_stripped, \"%d. %b. %Y, %H:%M\")\n",
    "        end_date.append(date_stripped)\n",
    "    \n",
    "    elif flat_starwars_info[i].findAll(\"span\", {\"class\": \"jss168\"}):\n",
    "        date = flat_starwars_info[i].findAll(\"span\", {\"class\": \"jss168\"})\n",
    "        date_stripped = date[0].get_text().strip(\"schedule\").replace(\"Dez\", \"Dec\")\n",
    "        \n",
    "        if len(date_stripped) > 25:\n",
    "            date_stripped = date_stripped[date_stripped.find('|'):].strip(\"| \")\n",
    "        \n",
    "        date_stripped = datetime.strptime(date_stripped, \"%d. %b. %Y, %H:%M\")\n",
    "        end_date.append(date_stripped)\n",
    "    \n",
    "    else:\n",
    "        end_date.append(\"NaN\")\n",
    "        \n",
    "for i in range(len(flat_duplo_info)):\n",
    "    if flat_duplo_info[i].findAll(\"span\", {\"class\": \"jss171\"}):\n",
    "        date = flat_duplo_info[i].findAll(\"span\", {\"class\": \"jss171\"})\n",
    "        date_stripped = date[0].get_text().strip(\"schedule\").replace(\"Dez\", \"Dec\")\n",
    "        \n",
    "        if len(date_stripped) > 25:\n",
    "            date_stripped = date_stripped[date_stripped.find('|'):].strip(\"| \")\n",
    "          \n",
    "        date_stripped = datetime.strptime(date_stripped, \"%d. %b. %Y, %H:%M\")\n",
    "        end_date.append(date_stripped)\n",
    "        \n",
    "    elif flat_duplo_info[i].findAll(\"span\", {\"class\": \"jss168\"}):\n",
    "        date = flat_duplo_info[i].findAll(\"span\", {\"class\": \"jss168\"})\n",
    "        date_stripped = date[0].get_text().strip(\"schedule\").replace(\"Dez\", \"Dec\")\n",
    "        \n",
    "        if len(date_stripped) > 25:\n",
    "            date_stripped = date_stripped[date_stripped.find('|'):].strip(\"| \")\n",
    "        \n",
    "        date_stripped = datetime.strptime(date_stripped, \"%d. %b. %Y, %H:%M\")\n",
    "        end_date.append(date_stripped)        \n",
    "        \n",
    "    else:\n",
    "        end_date.append(\"NaN\")\n",
    "        \n",
    "for i in range(len(flat_technic_info)):\n",
    "    if flat_technic_info[i].findAll(\"span\", {\"class\": \"jss171\"}):\n",
    "        date = flat_technic_info[i].findAll(\"span\", {\"class\": \"jss171\"})\n",
    "        date_stripped = date[0].get_text().strip(\"schedule\").replace(\"Dez\", \"Dec\")\n",
    "\n",
    "        if len(date_stripped) > 25:\n",
    "            date_stripped = date_stripped[date_stripped.find('|'):].strip(\"| \")\n",
    "  \n",
    "        date_stripped = datetime.strptime(date_stripped, \"%d. %b. %Y, %H:%M\")\n",
    "        end_date.append(date_stripped)\n",
    "        \n",
    "    elif flat_technic_info[i].findAll(\"span\", {\"class\": \"jss168\"}):\n",
    "        date = flat_technic_info[i].findAll(\"span\", {\"class\": \"jss168\"})\n",
    "        date_stripped = date[0].get_text().strip(\"schedule\").replace(\"Dez\", \"Dec\")\n",
    "        \n",
    "        if len(date_stripped) > 25:\n",
    "            date_stripped = date_stripped[date_stripped.find('|'):].strip(\"| \")\n",
    "        \n",
    "        date_stripped = datetime.strptime(date_stripped, \"%d. %b. %Y, %H:%M\")\n",
    "        end_date.append(date_stripped)        \n",
    "\n",
    "    else:\n",
    "        end_date.append(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lego_df[\"ends_on\"] = end_date\n",
    "lego_df[\"ends_on\"] = pd.to_datetime(lego_df[\"ends_on\"])\n",
    "lego_df[\"time_remaining\"] = lego_df[\"ends_on\"] - lego_df[\"scraped_at\"]\n",
    "lego_df[\"seconds_remaining\"] = lego_df[\"time_remaining\"].dt.seconds\n",
    "lego_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sale type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_type = list()\n",
    "\n",
    "for i in range(len(lego_df)):\n",
    "    if (lego_df[\"next_bid_auction\"].isna()[i] == False) & (lego_df[\"price_buy_now\"].isna()[i] == False):\n",
    "        sale_type.append(\"both\")\n",
    "    elif lego_df[\"next_bid_auction\"].isna()[i] == False:\n",
    "        sale_type.append(\"auction\")    \n",
    "    elif lego_df[\"price_buy_now\"].isna()[i] == False:\n",
    "        sale_type.append(\"buy_now\")\n",
    "    else:\n",
    "        sale_type.append(\"NaN\")\n",
    "        \n",
    "len(sale_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lego_df[\"sale_type\"] = sale_type\n",
    "lego_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lego_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lego_df.to_csv(f\"{datetime.now().strftime(\"%Y%m%d\")}_lego_sets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
